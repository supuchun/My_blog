-------------------人脸检测识别-----------------------
1、人脸检测：人脸检测得到面部候选框
	1）OpenCV
		1.Haar Cascade
		2.OpenCV DNN：最准确的
			1.原始Caffe实现的16位浮点型版本（5.4MB）
			2.TensorFlow实现的8位量化版本（2.7MB）
			
		OpenCV DNN人脸检测算法出自论文《SSD: Single Shot MultiBox Detector》，
		OpenCV提供了caffe和tensorflow两个版本，使用ResNet-10作为骨干网。
		
		OpenCV4.0 DNN人脸识别
			1、人脸检测模型实现对图像或者视频的人脸检测。
			2、对得到的人脸区域通过openface的预训练模型提取128个特征向量值，基于余弦相似度进行特征值比对，
				实现人脸识别。openface的原理又基于FaceNet
		
	2）Dlib
		1.HoG
		2.Dlib CNN
		
	3）face_recognition：基于Dlib开发的python库，它提供了非常有用的深度学习方法来查找和识别图像中的人脸。
			特别是face_locations、face_encodings和compare_faces函数是最有用的3个函数。
			face_locations方法可以使用两种方法检测人脸:梯度直方图(HoG)和卷积神经网络(CNN)。本文选择HoG方法。
			face_encodings函数是一个经过预处理的卷积神经网络，它能够将图像编码成包含128个特征的向量。
						这个嵌入向量应该表示足够的信息来区分两个不同的人。
			compare_faces计算两个嵌入向量之间的距离。它将允许我们识别从网络摄像头帧中提取的人脸，
						并将其嵌入向量与我们数据集中所有编码的人脸进行比较。最接近的向量应该对应于同一个人。
					
	4）facenet：Google的人脸识别库，基于MTCNN，采用端对端深度学习一个从图像到欧式空间的编码方法，
				然后基于这个编码再做人脸识别、人脸验证和人脸聚类等。
			FaceNet模型没有用传统的 softmax 的方式去进行分类学习，而是抽取其中某一层作为特征，
					学习一个从图像到欧式空间的编码方法，然后基于这个编码再做人脸识别、人脸验证和人脸聚类等。
			FaceNet 中采用基于深度神经网络的图像映射方法和基于 triplets（三联子）的 loss 函数训练神经网络，
					网络直接输出为 128 维度的向量空间。
					直接在欧几里德低维空间嵌入生成人脸特征，FaceNet仅需要128个字节来表示一张脸。
					
		附加：MTCNN（Multi-task Cascaded Convolutional Networks）人脸检测的深度学习模型
				MTCNN该模式是一种 Multi-task 的人脸检测框架，使用 3 个 CNN 级联算法结构，
				该模型中综合考虑了人脸边框回归和面部关键点检测，将人脸检测和人脸特征点检测同时进行。

2、人脸识别
	1）人脸检测得到面部候选框
	
    2）面部关键点定位，人脸特征提取
        1）Dlib提取人脸的68个特征点
        2）face_recognition提取的人脸特征比Dlib更加细致，达到128个点
        3）facenet（tf深度学习提取）提取的人脸特征的欧式空间的编码128个点
		
    3）面部特征匹配，识别
        1）KNN（小数据集，运算量小）
        2）欧氏距离（小数据集，运算量小）
		3）SVM（大数据集，运算量大）

-------------------目标检测-----------------------
1、one-stage：YOLO、SSD
    1）YOLO（You Only Look Once）：YOLOv1、YOLOv2、YOLOv3
		YOLO(You Only Look Once)是Joseph Redmon针对darknet框架提出的核心目标检测算法，用C和CUDA编写的端到端的实时目标检测系统。
    
	2）SSD（Single Shot MultiBox Detectorz）
	
		One-Stage目标检测算法：使用固定网格上的检测器，YOLOv3和SSD非常相似，尽管它们是通过不同的方法得到网格（YOLO使用升序采样，SSD使用降序采样）。
		One-Stage目标检测算法可以在一个stage直接产生物体的类别概率和位置坐标值，相比于Two-Stage的目标检测算法不需要Region Proposal阶段，整体流程较为简单。
    
2、two-stage：R-CNN系列,主要是2D的目标检测
    1）R-CNN
    2）Fast R-CNN
    3）Faster R-CNN：主要是2D的目标检测
		two-stage目标检测算法：基于候选框的目标检测方法，实际上Faster R-CNN中RPN网络也采用网格检测。
		Two-Stage目标检测算法可以看作是进行两次One-Stage检测，第一个Stage初步检测出物体位置，第二个Stage对第一个阶段的结果做进一步的精化，对每一个候选区域进行One-Stage检测。

3、Faster R-CNN、YOLO、SSD对比
    1）anchor boxes size取法不同
        SSD的anchor boxes是算出来的
        Faster-RCNN的是固定的
        YOLO是用数据集的gt boxes 通过kmeans算出来的
		
    2）feature extractor
        SSD：VGG
        YOLO：Darknet
        Faster-RCNN：Inception-Resnet v2
		
    3）Faster-RCNN慢的原因：Faster-RCNN在feature map每个像素点取9个anchor boxes之后proposal数量
	
    4）R-CNN 方法的缺点是它太慢了；由于它采用外部的候选框算法，它也不是一个完整的端到端 (end-to-end) 检测器。
		原理：
		(1) 预先找出图中物体可能出现的位置，即候选区域 (Region Proposal) 。利用图像中的纹理、边缘、颜色等信息，
			可以保证在选取较少窗口 (几千甚至几百) 的情况下保持较高的召回率 (Recall) 。
		(2) 然后将这些候选框送入CNN网络中进行识别分类。
			Fast R-CNN 相对R-CNN，Fast R-CNN算法有了很大改进，即提高了精确度，并减少了执行前向网络计算所需的时间；然而，该模型仍然依赖于外部的候选框算法。
			Faster-RCNN 通过使用区域生成网络 (Region Proposal Network, RPN)来取代候选框算法，Faster R-CNN 不是真正的端到端目标检测器。
    
    5）one-stage策略比two-stage策略的精度低，但速度快得多。
	
	6）相同点：把目标检测问题转换成关键点检测问题

6、常用的传统算法：Dlib：HOG+SVM
	HOG：对检测目标候选区域进行特征提取
	SVM：目标识别分类器

-------------------车牌识别-----------------------
1、算法流程：
	（1）采集车牌图像，预处理，车牌定位
	（2）提取字符，字符分割：灰度化 -> 二值化 -> 轮廓检测 –> 去除边框 ->轮廓检测 -> 
							大小筛选 -> 去除铆钉 –> 轮廓检测 -> 筛选 -> 重定位中文字符
	（3）字符模板匹配识别
	
2、模板匹配法：
	传统字符匹配算法：建立地域简称文字+26个大写字母表+0-9数字的数组集合
		1、逐像素点匹配
			1）遍历全部像素点，记录两张图中值不同的像素个数，除以全部像素数量即为匹配率。显然越接近0越匹配。
			2）逐个像素比对，如果一致则count加一，最后根据count值确定匹配结果。
			3）投影匹配：将每行、每列的像素位统计起来，根据差值大小来确定匹配结果。
		2、直方图匹配
		3、轮廓匹配
		4、Hu矩匹配
		
	SVM：训练支持向量机，收集10000张数字和字母的字符二值图。完成以下步骤：
	    1、依次读取每张字符二值图，得到它的数字矩阵（20行*20列的数组），然后转化为一个1*400的数组（即400列，每一列代表一个特征）。
	    2、遍历每一个字符照片，得到13156个1*400的一维数组，把它们合并成为一个13156*400（即13156行400列）的数据集。
	    3、A用10表示，Z用34表示，将数据集中每一行所对应的真实值作为类别标签，得到1*13156的类别数组。
	    4、导入机器学习模型当中进行训练，最后导入预测数据。

	CNN：训练神经网络，收集10000张数字、字母和各省简称的文字

-------------------U-net：医学图像分割-----------------------




    