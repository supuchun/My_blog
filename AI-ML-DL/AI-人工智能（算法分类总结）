算法分类总结
    1、贝叶斯分类器直接用贝叶斯公式解决分类问题 ，是一种生成模型，处理多分类问题，是一种非线性模型。
    2、决策树在本质上是一组嵌套的if-else判定规则，从数学上看是分段常数函数，对应于用平行于坐标轴的平面对空间的划分。决策树是一种判别模型，既支持分类问题，也支持回归问题，是一种非线性模型（分段线性函数不是线性的）。它天然的支持多分类问题。
    3、kNN算法本质上使用了模板匹配的思想。要确定一个样本的类别，可以计算它与所有训练样本的距离，然后找出和该样本最接近的k个样本，统计这些样本的类别进行投票，票数最多的那个类就是分类结果。
        kNN算法是一种判别模型，即支持分类问题，也支持回归问题，是一种非线性模型。它天然的支持多分类问题。kNN算法没有训练过程，是一种基于实例的算法。
    4、支持向量机的目标是寻找一个分类超平面，它不仅能正确的分类每一个样本，并且要使得每一类样本中距离超平面最近的样本到超平面的距离尽可能远。如果不使用非线性核函数，SVM是一个线性模型。
        训练时求解的问题是凸优化问题，求解采用了SMO算法，这是一种分治法，每次挑选出两个变量进行优化，其他变量保持不动。选择优化变量的依据是KKT条件，对这两个变量的优化是一个二次函数极值问题，
        可以直接得到公式解。SVM是一种判别模型。它既可以用于分类问题，也可以用于回归问题。标准的SVM只能支持二分类问题，使用多个分类器的组合，可以解决多分类问题。
    5、logistic回归核心：直接从样本估计出它属于正负样本的概率。通过先将向量进行线性加权，然后计算logistic函数，可以得到[0,1]之间的概率值，它表示样本x属于正样本的概率，正样本标签值为1，负样本为0。训练时，求解的的是对数似然函数。
        这是一个凸优化问题，求解时可以用梯度下降法，也可以用牛顿法。logistic回归是一种判别模型，需要注意的是它是一种线性模型，用于二分类问题。
    6、随机森林核心：用有放回采样的样本训练多棵决策树，训练决策树的每个节点是只用了无放回抽样的部分特征，预测时用这些树的预测结果进行投票。随机森林是一种集成学习算法，它由多棵决策树组成。
        对于分类问题，一个测试样本会送到每一棵决策树中进行预测，然后投票，得票最多的类为最终分类结果。对于回归问题随机森林的预测输出是所有决策树输出的均值。
        随机森林是一种判别模型，既支持分类问题，也支持回归问题，并且支持多分类问题。这是一种非线性模型。
    7、人工神经网络在本质上是一个多层的复合函数，它实现了从向量x到向量y的映射。由于使用了非线性的激活函数f，这个函数是一个非线性函数。神经网络训练时求解的问题不是凸优化问题。反向传播算法由多元复合函数求导的链式法则导出。
        标准的神经网络是一种有监督的学习算法，是一种非线性模型，它既可以用于分类问题，也可以用于回归问题，天然的支持多分类问题。
    8、卷积神经网络核心：一个共享权重的多层复合函数。卷积神经网络在本质上也是一个多层复合函数，但和普通神经网络不同的是它的某些权重参数是共享的，另外一个特点是它使用了池化层。训练时依然采用了反向传播算法，求解的问题不是凸优化问题。
        和全连接神经网络一样，卷积神经网络是一个判别模型，它既可以用于分类问题，也可以用用于回归问题，并且支持多分类问题。
    9、循环神经网络核心：综合了复合函数和递推数列的一个函数。和普通神经网络最大的不同在于，循环神经网络是一个递推的数列，因此具有了记忆功能。
        和其他类型的神经网络一样，循环神经网络是一个判别模型，既支持分类问题，也支持回归问题，并且支持多分类问题
    10、K均值算法核心：把样本分配到离它最近的类中心所属的类，类中心由属于这个类的所有样本确定。k均值算法是一种无监督的聚类算法。算法将每个样本分配到离它最近的那个类中心所代表的类，而类中心的确定又依赖于样本的分配方案。这是一个先有鸡还是先有蛋的问题。
        在实现时，先随机初始化每个类的类中心，然后计算样本与每个类的中心的距离，将其分配到最近的那个类，然后根据这种分配方案重新计算每个类的中心。这也是一种分阶段优化的策略。
        k均值算法要求解的问题是一个NPC问题，只能近似求解，有陷入局部极小值的风险。



