1、机器学习
        机器学习的应用--大数据:数据挖掘与数据分析
        机器学习的子类--深度学习
        机器学习的父类，人工智能
        机器学习的思考--计算机的潜意识
2、机器学习是一种让计算机利用数据而不是指令来进行各种工作的方法。机器学习方法是计算机利用已有的数据(经验)，得出了某种模型(迟到的规律)   
    并利用此模型预测未来(是否迟到)的一种方法。
   机器学习的一个主要目的就是把人类思考归纳经验的过程转化为计算机通过对数据的处理计算得出模型的过程。经过计算机得出的模型能够以近似于人的方式解决很多灵活复杂的问题。
    从广义上来说，机器学习是一种能够赋予机器学习的能力以此让它完成直接编程无法完成的功能的方法。但从实践的意义上来说，机器学习是一种通过利用数据训练出模型，然后使用模型预测的一种方法。
3、一般来说(不是绝对)，数据越多，最后机器学习生成的模型预测的效果越好。机器学习中的“训练”与“预测”过程可以对应到人类的“归纳”和“推测”过程。
    数据通过机器学习算法进行处理，这个过程在机器学习中叫做“训练”，处理的结果可以被我们用来对新的数据进行预测，这个结果一般称之为“模型”。
    对新数据 的预测过程在机器学习中叫做“预测”。“训练”与“预测”是机器学习的两个过程，“模型”则是过程的中间输出结果，“训练”产生“模型”，“模型”指导 “预测”。
4、机器学习的范围
        模式识别=机器学习
        数据挖掘=机器学习+数据库：大部分数据挖掘中的算法是机器学习的算法在数据库中的优化。
        统计学习近似等于机器学习：机器学习中的大多数方法来自统计学，甚至可以认为，统计学的发展促进机器学习的繁荣昌盛。分别在于：统计学习者重点关注的是统计模型的发展与优化，偏数学，而机器学习者更关注的是能够解决问题，偏实践
        计算机视觉=图像处理+机器学习
        语音识别=语音处理+机器学习
        自然语言处理=文本处理+机器学习
5、机器学习的方法
        1、回归算法:回归算法有两个重要的子类：即线性回归和逻辑回归。
                   线性回归：进行直线或曲线拟合，一般使用“最小二乘法”来求解。最小二乘法将最优问题转化为求函数极值问题。函数极值在数学上我们一般会采用求导数为0的方法。
                            但这种做法并不适合计算机，可能求解不出来，也可能计算量太大。计算机科学界专门有一个学科叫“数值计算”，专门用来提升计算机进行各类计算时的准确性和效率问题。
                            例如，著名的“梯度下降”以及“牛顿法”就是数值计算中的经典算法，也非常适合来处理求解函数极值的问题。梯度下降法是解决回归模型中最简单且有效的方法之一。
                            从严格意义上来说，由于后文中的神经网络和推荐算法中都有线性回归的因子，因此梯度下降法在后面的算法实现中也有应用。
                   逻辑回归：线性回归处理的是数值问题，也就是最后预测出的结果是数字。而逻辑回归属于分类算法，也就是说，逻辑回归预测结果是离散的分类，例如判断这封邮件是否是垃圾邮件，
                            以及用户是否会点击此广告等等。实现方面的话，逻辑回归只是对对线性回归的计算结果加上了一个Sigmoid函数，将数值结果转化为了0到1之间的概率(Sigmoid函数的图像一般来说并不直观，你只需要理解对数值越大，
                            函数越逼近1，数值越小，函数越逼近0)，接着我们根据这个概率可以做预测，例如概率大于0.5，则这封邮件就是垃圾邮件，或者肿瘤是否是恶性的等等
                            下面的两个算法是机器学习界最强大且重要的算法，都可以拟合出非线性的分类线。
        2、神经网络：机器学习的学者们使用神经网络进行机器学习的实验，发现在视觉与语音的识别上效果都相当好。
                    一个简单的神经网络的逻辑架构。在这个网络中，分成输入层，隐藏层，和输出层。输入层负责接收信号，隐藏层负责对数据的分解与处理，最后的结果被整合到输出层。每层中的一个圆代表一个处理单元，
                    可以认为是模拟了一个神经元，若干个处理单元组成了一个层，若干个层再组成了一个网络，也就是"神经网络"。在神经网络中，每个处理单元事实上就是一个逻辑回归模型，逻辑回归模型接收上层的输入，
                    把模型的预测结果作为输出传输到下一个层次。通过这样的过程，神经网络可以完成非常复杂的非线性分类。
        3、SVM（支持向量机）：支持向量机算法是诞生于统计学习界
                    支持向量机算法从某种意义上来说是逻辑回归算法的强化：通过给予逻辑回归算法更严格的优化条件，支持向量机算法可以获得比逻辑回归更好的分类界线。但是如果没有某类函数技术，
                    则支持向量机算法最多算是一种更好的线性分类技术。但是，通过跟高斯“核”的结合，支持向量机可以表达出非常复杂的分类界线，从而达成很好的的分类效果。“核”事实上就是一种特殊的函数，
                    最典型的特征就是可以将低维的空间映射到高维的空间。
        4、聚类算法：算法中，训练数据都是不含标签的，而算法的目的则是通过训练，推测出这些数据的标签。这类算法有一个统称，即无监督算法(                        前面有标签的数据的算法则是有监督算法)。
                    无监督算法中最典型的代表就是聚类算法。聚类算法就是计算种群中的距离，根据距离的远近将数据划分为多个族群。聚类算法中最典型的代表就是K-Means算法。
        5、降维算法：降维算法也是一种无监督学习算法，其主要特征是将数据从高维降低到低维层次。在这里，维度其实表示的是数据的特征量的大小，例如，房            价包含房子的长、宽、面积与房间数量四个特征，
                    也就是维度为4维的数据。可以看出来，长与宽事实上与面积表示的信息重叠了，例如面积=长 × 宽。通过降维算法我们就可以去除冗余信息，将特征减少为面积与房间数量两个特征，即从4维的数据压缩到2维。
                    于是我们将数据从高维降低到低维，不仅利于表示，同时在计算上也能带来加速。降维算法的主要作用是压缩数据与提升机器学习其他算法的效率。通过降维算法，可以将具有几千个特征的数据压缩至若干个特征。
                    另外，降维算法的另一个好处是数据的可视化，例如将5维的数据压缩至2维，然后可以用二维平面来可视。降维算法的主要代表是PCA算法(即主成分分析算法)。
        6、推荐算法：推荐算法的主要特征就是可以自动向用户推荐他们最感兴趣的东西，从而增加购买率，提升效益。推荐算法有两个主要的类别：一类是基于物品内容的推荐，是将与用户购买的内容近似的物品推荐给用户。
                    另一类是基于用户相似度的推荐，则是将与目标用户兴趣相同的其他用户购买的东西推荐给目标用户。两类推荐都有各自的优缺点，在一般的电商应用中，一般是两类混合使用。推荐算法中最有名的算法就是协同过滤算法。
        7、其他：机器学习界还有其他的如高斯判别，朴素贝叶斯，决策树等等算法。但是上面列的六个算法是使用最多，影响最广，种类最全的典型。机器学习界的一个特色就是算法众多，发展百花齐放。
                总结，按照训练的数据有无标签，可以将上面算法分为监督学习算法和无监督学习算法，但推荐算法较为特殊，既不属于监督学习，也不属于非监督学习，是单独的一类。
                监督学习算法：线性回归，逻辑回归，神经网络，SVM
                无监督学习算法： 聚类算法，降维算法
                特殊算法：推荐算法
        一些算法的名字在机器学习领域中也经常出现。但他们本身并不算是一个机器学习算法，而是为了解决某个子问题而诞生的机器学习算法的子算法，用于大幅度提高训练过程。其中的代表有：梯度下降法，
        主要运用在线型回归，逻辑回归，神经网络，推荐算法中；牛顿法，主要运用在线型回归中；BP算法，主要运用在神经网络中；SMO算法，主要运用在SVM中。
6、机器学习的应用--大数据
   机器学习大量的应用都与大数据高度耦合，几乎可以认为大数据是机器学习应用的最佳场景。正是基于机器学习技术的应用，数据才能发挥其魔力。大数据的核心是利用数据的价值，机器学习是利用数据价值的关键技术。
   对于机器学习而言，越多的数据会越 可能提升模型的精确性，同时，复杂的机器学习算法的计算时间也迫切需要分布式计算与内存计算这样的关键技术。
   大数据并不等同于机器学习，同理，机器学习也不等同于大数据。大数据中包含有分布式计算，内存数据库，多维分析等等多种技术。单从分析方法来看，大数据也包含以下四种分析方法：
        1.大数据，小分析：即数据仓库领域的OLAP分析思路，也就是多维分析思想。
        2.大数据，大分析：这个代表的就是数据挖掘与机器学习分析法。 机器学习仅仅是大数据分析中的一种而已。
        3.流式分析：这个主要指的是事件驱动架构。
        4.查询分析：经典代表是NoSQL数据库。
7、机器学习的子类--深度学习
    深度学习这四字听起来颇为高大上，但其理念却非常简单，就是传统的神经网络发展到了多隐藏层的情况。神经网络在隐藏层扩大到两个以上，其训练速度就会非常慢。
        1.多隐层的神经网络具有优异的特征学习能力，学习得到的特征对数据有更本质的刻画，从而有利于可视化或分类；
    　　2.深度神经网络在训练上的难度，可以通过“逐层初始化” 来有效克服。
    具有多个隐藏层的神经网络被称为深度神经网络，基于深度神经网络的学习研究称之为深度学习。
8、机器学习的父类--人工智能
    机器学习的内核思想统计和归纳
9、机器学习的过程会包含以下三步： 
        获取与处理数据；
        选择与训练模型；
        评估与可视化结果
10、机器学习
    无监督算法机器学习主要的分类包含： 
        - 聚类算法 (代表：K均值聚类，系统聚类) 
        - 降维算法 （代表：主成份分析PCA，线性判断分析LDA）
    有监督算法机器学习主要的分类包含： 
        - 回归算法 (线性回归，最小二乘回归，LOESS局部回归，神经网路，深度学习） 
        - 分类算法（决策树，支持向量机，贝叶斯，K-近邻算法，逻辑回归，随机森林）
11、激活函数可以引入非线性因素，解决线性模型所不能解决的问题
12、偏置单元与后一层的所有节点都有连接，我们设这些参数值为向量b，称之为偏置，存储值永远为1的单元。
13、在单层神经网络时，我们使用的激活函数是sgn函数。到了两层神经网络时，我们使用的最多的是sigmoid函数。而到了多层神经网络时，通过一系列的研究发现，ReLU函数在训练多层神经网络时，更容易收敛，
    并且预测性能更好。因此，目前在深度学习中，最流行的非线性函数是ReLU函数。ReLU函数不是传统的非线性函数，而是分段线性函数。其表达式非常简单，就是y=max(x,0)。简而言之，在x大于0，输出就是输入，
    而在x小于0时，输出就保持为0。这种函数的设计启发来自于生物神经元对于激励的线性响应，以及当低于某个阈值后就不再响应的模拟。
14、梯度下降算法以及反向传播算法在多层神经网络中的训练中工作的很好，神经网络内部实际上就是矩阵计算
15、BP（Back Propagation）神经网络分为两个过程
      （1）工作信号正向传递子过程
      （2）误差信号反向传递子过程
      BP网络（Back Propagation），是1986年由Rumelhart和McCelland为首的科学家小组提出，是一种按误差逆传播算法训练的多层前馈网络，是目前应用最广泛的神经网络模型之一
16、Deep learning本身算是machine learning的一个分支，简单可以理解为neural network的发展。  Deep learning与传统的神经网络之间有相同的地方也有很多不同。
    二者的相同在于deep learning采用了神经网络相似的分层结构，系统由包括输入层、隐层（多层）、输出层组成的多层网络，只有相邻层节点之间有连接，同一层以及跨层节点之间相互无连接，
    每一层可以看作是一个logistic regression模型；这种分层结构，是比较接近人类大脑的结构的。
    为了克服神经网络训练中的问题，DL采用了与神经网络很不同的训练机制。传统神经网络中，采用的是back propagation的方式进行，简单来讲就是采用迭代的算法来训练整个网络，随机设定初值，
    计算当前网络的输出，然后根据当前输出和label之间的差去改变前面各层的参数，直到收敛（整体是一个梯度下降法）。而deep learning整体上是一个layer-wise的训练机制。这样做的原因是因为，
    如果采用back propagation的机制，对于一个deep network（7层以上），残差传播到最前面的层已经变得太小，出现所谓的gradient diffusion（梯度扩散）。
17、把数据“投喂”给普适算法，然后它会在数据上建立自己的逻辑。
18、以下是最常用的机器学习算法，大部分数据问题都可以通过它们解决： 
        1.线性回归 (Linear Regression) 
        2.逻辑回归 (Logistic Regression) 
        3.决策树 (Decision Tree) 
        4.支持向量机（SVM） 
        5.朴素贝叶斯 (Naive Bayes) 
        6.K邻近算法（KNN） 
        7.K-均值算法（K-means） 
        8.随机森林 (Random Forest) 
        9.降低维度算法（DimensionalityReduction Algorithms） 
        10.GradientBoost和Adaboost算法
19、开发机器学习应用程序的步骤
    （1）收集数据
        我们可以使用很多方法收集样本护具，如：制作网络爬虫从网站上抽取数据、从RSS反馈或者API中得到信息、设备发送过来的实测数据。
    （2）准备输入数据
        得到数据之后，还必须确保数据格式符合要求。
    （3）分析输入数据
        这一步的主要作用是确保数据集中没有垃圾数据。如果是使用信任的数据来源，那么可以直接跳过这个步骤
    （4）训练算法
        机器学习算法从这一步才真正开始学习。如果使用无监督学习算法，由于不存在目标变量值，故而也不需要训练算法，所有与算法相关的内容在第（5）步
    （5）测试算法
        这一步将实际使用第（4）步机器学习得到的知识信息。当然在这也需要评估结果的准确率，然后根据需要重新训练你的算法
    （6）使用算法
        转化为应用程序，执行实际任务。以检验上述步骤是否可以在实际环境中正常工作。如果碰到新的数据问题，同样需要重复执行上述的步骤
20、机器学习的一般框架
    训练集 => 提取特征向量 => 结合一定的算法（分类器：比如决策树，KNN）=>得到结果
21、梯度下降算法的正确步骤
        a.用随机值初始化权重和偏差
        b.把输入传入网络，得到输出值
        c.计算预测值和真实值之间的误差
        d.对每一个产生误差的神经元，调整相应的（权重）值以减小误差
        e.重复迭代，直至得到网络权重的最佳值